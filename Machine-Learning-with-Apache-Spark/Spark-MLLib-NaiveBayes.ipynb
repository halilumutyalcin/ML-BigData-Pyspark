{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Classification - Decision Tree </strong>\n",
    "<ul style=\"list-style-type:square\">\n",
    "  <li>Features :  SMS</li>\n",
    "  <li>Target : ham/spam </li>\n",
    "  <li>Model : Naive Bayes</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Attribute Information: </strong>\n",
    "<ul style=\"list-style-type:square\">\n",
    "\n",
    "<strong>The collection is composed by just one text file, where each line has the correct class followed by the raw message. We offer some examples bellow: </strong>\n",
    "\n",
    "  <li> ham What you doing?how are you?</li>\n",
    "  <li>ham Ok lar... Joking wif u oni... </li>\n",
    "  <li>ham dun say so early hor... U c already then say...</li>\n",
    "  <li>ham MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*   </i>\n",
    "  <li>ham Siva is in hostel aha:-. </i>\n",
    "  <li>ham Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor    </i>\n",
    "  <li>spam FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop</i>\n",
    "  <li>spam Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B</i>\n",
    "  <li>spam URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU</i> </ul>\n",
    " \n",
    "Note: the messages are not chronologically sorted.\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "  \n",
    "   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMS spam message Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"NaiveBayes\").config(\"some.config\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer # natural language processing\n",
    "# The inverse document frequency (IDF) tells us how important a term is to a collection of documents.\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator # To evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMSSpamCollection.CSV MapPartitionsRDD[5] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import CSV and Store the RDD in cache\n",
    "spamRDD = sc.textFile(\"SMSSpamCollection.CSV\")\n",
    "spamRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...,,,,,,,,,',\n",
       " 'ham,Ok lar... Joking wif u oni...,,,,,,,,,,',\n",
       " 'ham,U dun say so early hor... U c already then say...,,,,,,,,,,',\n",
       " \"ham,Nah I don't think he goes to usf, he lives around here though,,,,,,,,,\",\n",
       " 'ham,Even my brother is not like to speak with me. They treat me like aids patent.,,,,,,,,,,',\n",
       " \"ham,As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune,,,,,,,,,,\",\n",
       " \"ham,I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.,,,,,,,,,\",\n",
       " \"ham,I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.,,,,,,,,,,\",\n",
       " 'ham,I HAVE A DATE ON SUNDAY WITH WILL!!,,,,,,,,,,',\n",
       " \"ham,Oh k...i'm watching here:),,,,,,,,,,\",\n",
       " 'ham,Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.,,,,,,,,,,',\n",
       " 'ham,Fine if that\\x92s the way u feel. That\\x92s the way its gota b,,,,,,,,,,',\n",
       " 'ham,Is that seriously how you spell his name?,,,,,,,,,,',\n",
       " 'ham,I‘m going to try for 2 months ha ha only joking,,,,,,,,,,',\n",
       " 'ham,So ü pay first lar... Then when is da stock comin...,,,,,,,,,,']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spamRDD.collect()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Provessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def TransformVector(inputString):\n",
    "    # split data\n",
    "    attList = inputString.split(\",\")\n",
    "    # Set numeric label\n",
    "    smsType = 0.0 if attList[0] == \"ham\" else 1.0\n",
    "    return [smsType, attList[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|Go until jurong p...|\n",
      "|  0.0|Ok lar... Joking ...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|Nah I don't think...|\n",
      "|  0.0|Even my brother i...|\n",
      "|  0.0|As per your reque...|\n",
      "|  0.0|I'm gonna be home...|\n",
      "|  0.0|I've been searchi...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  0.0|Oh k...i'm watchi...|\n",
      "|  0.0|Eh u remember how...|\n",
      "|  0.0|Fine if thats th...|\n",
      "|  0.0|Is that seriously...|\n",
      "|  0.0|I‘m going to try ...|\n",
      "|  0.0|So ü pay first la...|\n",
      "|  0.0|Aft i finish my l...|\n",
      "|  0.0|Ffffffffff. Alrig...|\n",
      "|  0.0|Just forced mysel...|\n",
      "|  0.0|Lol your always s...|\n",
      "|  0.0|Did you catch the...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply TranformVector Fuction\n",
    "# transform rdd into datagrame\n",
    "spamRDD2 = spamRDD.map(TransformVector)\n",
    "spamDF = spSession.createDataFrame(spamRDD2,[\"label\", \"message\"])\n",
    "spamDF.cache()\n",
    "spamDF.select(\"label\", \"message\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "[training_set, test_set] = spamDF.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split words and Apply TF-IDF\n",
    "# Tokanize sms into words\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=  \"words\")\n",
    "# Generate the term frequency vector\n",
    "hashingTF = HashingTF( inputCol= tokenizer.getOutputCol(), outputCol=\"tempfeatures\")\n",
    "# Count word with low frequency\n",
    "idf = IDF(inputCol= hashingTF.getOutputCol(), outputCol=\"features\")\n",
    "# Algorithm\n",
    "nbClassifier = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline\n",
    "pipeline = Pipeline(stages = [tokenizer,hashingTF,idf,nbClassifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model with pipeline\n",
    "model = pipeline.fit(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "predictions = model.transform(test_set)\n",
    "predictions.select(\"prediction\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243986254295533"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accruray of the Model\n",
    "accuracy = MulticlassClassificationEvaluator( predictionCol= \"prediction\", labelCol= \"label\", metricName=\"accuracy\")\n",
    "accuracy.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|prediction|label|count|\n",
      "+----------+-----+-----+\n",
      "|       1.0|  1.0|  141|\n",
      "|       0.0|  1.0|    7|\n",
      "|       1.0|  0.0|   15|\n",
      "|       0.0|  0.0|  128|\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "predictions.groupBy(\"prediction\",\"label\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
